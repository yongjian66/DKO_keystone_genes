{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import csv\n",
    "import itertools\n",
    "import math\n",
    "import os.path\n",
    "import pdb\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from collections import Counter\n",
    "from itertools import permutations, product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from scipy.integrate import odeint, solve_ivp\n",
    "from scipy.spatial.distance import braycurtis\n",
    "from scipy.stats import entropy, pearsonr, spearmanr\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.spatial.distance import braycurtis\n",
    "np.set_printoptions(suppress=True, precision=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DKO Model\n",
    "def get_batch(ztrn,ptrn,mb_size):\n",
    "    s = torch.from_numpy(np.random.choice(np.arange(ptrn.size(dim=0), dtype=np.int64), mb_size, replace=False))\n",
    "    batch_p = ztrn[s,:]\n",
    "    batch_q = ptrn[s,:]\n",
    "    batch_t = t[:batch_time]\n",
    "    return batch_p.to(device), batch_q.to(device)\n",
    "\n",
    "\n",
    "def loss_bc(p_i,q_i):\n",
    "    return torch.sum(torch.abs(p_i-q_i))/torch.sum(torch.abs(p_i+q_i))\n",
    "\n",
    "\n",
    "def process_data(P):\n",
    "    #Z = P.copy()\n",
    "    #Z[Z!=0] = 1\n",
    "    P = P/P.sum(axis=0)[np.newaxis,:]\n",
    "    #Z = Z/Z.sum(axis=0)[np.newaxis,:]\n",
    "    \n",
    "   \n",
    "    P = P.astype(np.float32)\n",
    "#     Z = Z.astype(np.float32)\n",
    "\n",
    "    P = torch.from_numpy(P.T)\n",
    "    #Z = torch.from_numpy(Z.T)\n",
    "    return P\n",
    "\n",
    "\n",
    "class ODEFunc(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ODEFunc, self).__init__()\n",
    "        self.fcc1 = torch.nn.Linear(N, N)\n",
    "        self.fcc2 = torch.nn.Linear(N, N)\n",
    "\n",
    "    def forward(self, y):\n",
    "        out = self.fcc1(y)\n",
    "        out = self.fcc2(out)\n",
    "        return torch.mul(y,torch.abs(out))/torch.sum(torch.mul(y,torch.abs(out)))\n",
    "    \n",
    "def train_reptile(max_epochs,mb,LR,ztrn,ptrn,ztst,ptst,zval,pval,zall,pall):\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "    qtst = np.zeros((ztst.size(dim=0),N))\n",
    "    qtrn = np.zeros((zall.size(dim=0),N))\n",
    "    ltst_pred = np.zeros((ztst.size(dim=0),1))\n",
    "    ltst_ground = np.zeros((ztst.size(dim=0),1))\n",
    "    \n",
    "    func = ODEFunc().to(device)\n",
    "    optimizer = torch.optim.Adam(func.parameters(), lr=LR)\n",
    "\n",
    "    Loss_opt = 1\n",
    "    for e in range(max_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        batch_p, batch_q = get_batch(ztrn,ptrn,mb)\n",
    "        \n",
    "        # loss of the traning set\n",
    "        for i in range(mb):\n",
    "            p_pred = func(batch_p[i]).to(device)\n",
    "            p_pred = torch.reshape(p_pred,(1,N))\n",
    "            if i==0:\n",
    "                loss = loss_bc(p_pred.unsqueeze(dim=0),batch_q[i].unsqueeze(dim=0))\n",
    "            else:\n",
    "                loss = loss + loss_bc(p_pred.unsqueeze(dim=0),batch_q[i].unsqueeze(dim=0))\n",
    "        loss_train.append(loss.item()/mb)\n",
    "\n",
    "\n",
    "        # validation set\n",
    "        for i in range(zval.size(dim=0)):\n",
    "            p_pred = func(zval[i]).to(device)\n",
    "            p_pred = torch.reshape(p_pred,(1,N))\n",
    "            if i==0:\n",
    "                l_val = loss_bc(p_pred.unsqueeze(dim=0),pval[i].unsqueeze(dim=0))\n",
    "            else:\n",
    "                l_val = l_val + loss_bc(p_pred.unsqueeze(dim=0),pval[i].unsqueeze(dim=0))\n",
    "        loss_val.append(l_val.item()/zval.size(dim=0))\n",
    "        if l_val.item()/zval.size(dim=0)<=Loss_opt:\n",
    "            Loss_opt = loss_val[-1]\n",
    "            best_model = copy.deepcopy(func)\n",
    "        #print('epoch = ',e, 'loss = ', l_val.item()/mb)\n",
    "\n",
    "        # update the neural network\n",
    "        func.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e == max_epochs-1:\n",
    "            func = copy.deepcopy(best_model)\n",
    "            if len(ztst.size())==2:\n",
    "                for i in range(ztst.size(dim=0)):\n",
    "                    pred_test = func(ztst[i]).to(device)\n",
    "                    pred_test = torch.reshape(pred_test,(1,N))\n",
    "                    qtst[i,:] = pred_test.detach().numpy()\n",
    "                for i in range(zall.size(dim=0)):\n",
    "                    pred_test = func(zall[i]).to(device)\n",
    "                    pred_test = torch.reshape(pred_test,(1,N))\n",
    "                    qtrn[i,:] = pred_test.detach().numpy()\n",
    "    return loss_train,qtst,qtrn\n",
    "\n",
    "def ode_act_and_rep(t, x, B, W_act, W_rep, frozen_idx): \n",
    "    dxdt = np.zeros_like(x)\n",
    "    for j in range(len(x)):  # target genes (regulated nodes)\n",
    "        if j in frozen_idx:\n",
    "            continue  # frozen targets are not updated\n",
    "\n",
    "        activation_sum = 0.0\n",
    "        repression_sum = 0.0\n",
    "        for i in range(len(x)):  # regulators\n",
    "            if i in frozen_idx:\n",
    "                continue  # frozen regulators do not participate in regulation\n",
    "\n",
    "            if W_act[i, j] != 0:\n",
    "                activation_sum += W_act[i, j] * (x[i] / (1 + x[i]))\n",
    "            if W_rep[i, j] != 0:\n",
    "                repression_sum += W_rep[i, j] * (1 / (1 + x[i]))\n",
    "\n",
    "        dxdt[j] = -B * x[j] + activation_sum + repression_sum\n",
    "\n",
    "    dxdt[frozen_idx] = 0.0  # enforce freezing at the end (extra safety)\n",
    "    return dxdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling double-KO: 100%|█████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 27889.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ztst shape: torch.Size([500, 100])\n",
      "qtst shape: (500, 100)\n",
      "     gene1_id  gene2_id  cell_id    k_pred\n",
      "0           4        16      425  0.076976\n",
      "1           8        45      182  0.045585\n",
      "2          36        84      321  0.055198\n",
      "3          71        88      352  0.027712\n",
      "4          10        63      429  0.065817\n",
      "..        ...       ...      ...       ...\n",
      "495        19        27      253  0.061564\n",
      "496        35        78      422  0.053803\n",
      "497        14        77      476  0.035865\n",
      "498        57        81      239  0.026167\n",
      "499        27        40      338  0.110980\n",
      "\n",
      "[500 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "N_cells = 500\n",
    "N_genes = 100\n",
    "\n",
    "###################### Step 1: Generate double-KO test data ####################\n",
    "Orignial = pd.read_csv(\n",
    "    f'./data/Ptrain.csv',\n",
    "    header=None\n",
    ").values.astype(np.float32)   # genes × cells\n",
    "\n",
    "N_genes, N_cells = Orignial.shape\n",
    "n_samples = 50000 ###randomly select 50000 double-gene KO samples\n",
    "rng = np.random.default_rng(2026)\n",
    "\n",
    "nz_per_cell = [np.flatnonzero(Orignial[:, c]) for c in range(N_cells)]\n",
    "eligible_cells = np.array([c for c in range(N_cells) if nz_per_cell[c].size >= 2], dtype=int)\n",
    "\n",
    "\n",
    "perturb_matrix = np.zeros((N_genes, n_samples), dtype=np.float32)\n",
    "records = np.zeros((n_samples, 3), dtype=int)  # cell, g1, g2\n",
    "\n",
    "seen = set()\n",
    "k = 0\n",
    "pbar = tqdm(total=n_samples, desc=\"Sampling double-KO\")\n",
    "\n",
    "while k < n_samples:\n",
    "    cell = int(rng.choice(eligible_cells))\n",
    "    genes = nz_per_cell[cell]\n",
    "    g1, g2 = rng.choice(genes, size=2, replace=False)\n",
    "    g1, g2 = int(g1), int(g2)\n",
    "    if g1 > g2: g1, g2 = g2, g1  # canonicalize ordering to avoid (a,b) and (b,a) duplicates\n",
    "\n",
    "    key = (cell, g1, g2)\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "\n",
    "    x = Orignial[:, cell].copy()\n",
    "    x[g1] = 0.0\n",
    "    x[g2] = 0.0\n",
    "\n",
    "    perturb_matrix[:, k] = x\n",
    "    records[k] = key\n",
    "    k += 1\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "pd.DataFrame(perturb_matrix).to_csv(\n",
    "    f'./data/Ptest_doubleKO.csv',\n",
    "    header=None, index=None\n",
    ")\n",
    "pd.DataFrame(records, columns=[\"cell_index\", \"gene1_index\", \"gene2_index\"]).to_csv(\n",
    "    f'./data/Recorder_doubleKO.csv',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "################## Step 2: Predict profiles #################\n",
    "max_epochs = 5000\n",
    "device = 'cpu'\n",
    "batch_time = 100\n",
    "t = torch.arange(0.0, 100.0, 0.01)\n",
    "\n",
    "# ---------- Training set ----------\n",
    "filepath_train = f'./data/Ptrain.csv'\n",
    "P = np.loadtxt(filepath_train, delimiter=',')  # (N_genes, N_cells)\n",
    "\n",
    "Z = P.copy()\n",
    "Z[Z > 0] = 1\n",
    "\n",
    "pall = process_data(P)\n",
    "zall = process_data(Z)\n",
    "\n",
    "number_of_cols = P.shape[1]\n",
    "random_indices = np.random.choice(number_of_cols, size=int(0.2 * number_of_cols), replace=False)\n",
    "\n",
    "P_val = P[:, random_indices]\n",
    "Z_val = Z[:, random_indices]\n",
    "\n",
    "P_train = P[:, np.setdiff1d(np.arange(number_of_cols), random_indices)]\n",
    "Z_train = Z[:, np.setdiff1d(np.arange(number_of_cols), random_indices)]\n",
    "\n",
    "ptrn = process_data(P_train)\n",
    "pval = process_data(P_val)\n",
    "ztrn = process_data(Z_train)\n",
    "zval = process_data(Z_val)\n",
    "\n",
    "# ---------- Double-KO test set ----------\n",
    "filepath_test = f'./data/Ptest_doubleKO.csv'\n",
    "P1 = np.loadtxt(filepath_test, delimiter=',')  # (N_genes, C)\n",
    "Z1 = P1.copy()\n",
    "Z1[Z1 > 0] = 1\n",
    "\n",
    "ptst = process_data(P1)\n",
    "ztst = process_data(Z1)\n",
    "\n",
    "M, N = ptrn.shape\n",
    "print(\"ztst shape:\", ztst.shape)\n",
    "\n",
    "# Pre-training to select hyperparameters\n",
    "LR = 0.01\n",
    "mb = 20\n",
    "\n",
    "loss_train, qtst, qtrn = train_reptile(\n",
    "    max_epochs, mb, LR,\n",
    "    ztrn, ptrn,\n",
    "    ztst, ptst,\n",
    "    zval, pval,\n",
    "    zall, pall\n",
    ")\n",
    "\n",
    "np.savetxt(\n",
    "    f'./data/PredDoubleKO.csv',\n",
    "    qtst, delimiter=',', fmt='%.6f'\n",
    ")\n",
    "\n",
    "np.savetxt(\n",
    "    f'./data/PPredDouble.csv',\n",
    "    qtrn, delimiter=',', fmt='%.6f'\n",
    ")\n",
    "print(\"qtst shape:\", qtst.shape)\n",
    "\n",
    "############## Step 3: Compute KO impact ##############\n",
    "# ---------- Load double-KO records ----------\n",
    "records = pd.read_csv(f'./data/Recorder_doubleKO.csv')\n",
    "Perturb_cell_index  = records['cell_index'].astype(int).to_numpy()\n",
    "Perturb_gene1_index = records['gene1_index'].astype(int).to_numpy()\n",
    "Perturb_gene2_index = records['gene2_index'].astype(int).to_numpy()\n",
    "\n",
    "# ---------- Baseline & prediction ----------\n",
    "Original = np.loadtxt(f'./data/Ptrain.csv', delimiter=',')  # (N_genes, N_cells)\n",
    "\n",
    "Original_model = np.loadtxt(\n",
    "    f'./data/PPredDouble.csv',\n",
    "    delimiter=','\n",
    ")\n",
    "\n",
    "predss = np.loadtxt(\n",
    "    f'./data/PredDoubleKO.csv',\n",
    "    delimiter=','\n",
    ")  # (C, N_genes)\n",
    "\n",
    "N_genes, N_cells = Original.shape\n",
    "\n",
    "def get_baseline_from_true_matrix(mat_genes_by_cells, cell_id):\n",
    "    x = mat_genes_by_cells[:, cell_id].copy()\n",
    "    s = x.sum()\n",
    "    return x / s if s > 0 else x\n",
    "\n",
    "def get_baseline_from_model_matrix(model_mat, cell_id, N_genes, N_cells):\n",
    "    \"\"\"\n",
    "    Support two common shapes:\n",
    "    - (N_cells, N_genes): use model_mat[cell_id, :]\n",
    "    - (N_genes, N_cells): use model_mat[:, cell_id]\n",
    "    \"\"\"\n",
    "    if model_mat.shape == (N_cells, N_genes):\n",
    "        x = model_mat[cell_id, :].copy()\n",
    "    elif model_mat.shape == (N_genes, N_cells):\n",
    "        x = model_mat[:, cell_id].copy()\n",
    "    else:\n",
    "        # Fallback: infer which axis corresponds to N_genes\n",
    "        if model_mat.shape[1] == N_genes:\n",
    "            x = model_mat[cell_id, :].copy()\n",
    "        elif model_mat.shape[0] == N_genes:\n",
    "            x = model_mat[:, cell_id].copy()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Original_model shape={model_mat.shape} cannot align with \"\n",
    "                f\"(N_genes,N_cells)=({N_genes},{N_cells})\"\n",
    "            )\n",
    "\n",
    "    s = x.sum()\n",
    "    return x / s if s > 0 else x\n",
    "\n",
    "p_dis = []\n",
    "\n",
    "for i in range(predss.shape[0]):\n",
    "    c_id = int(Perturb_cell_index[i])\n",
    "\n",
    "    # Baseline (true unperturbed expression)\n",
    "    Without_knock = get_baseline_from_true_matrix(Original, c_id)\n",
    "\n",
    "    # Baseline (model-predicted unperturbed expression)\n",
    "    Without_knock1 = get_baseline_from_model_matrix(Original_model, c_id, N_genes, N_cells)\n",
    "\n",
    "    one_pred = predss[i, :]\n",
    "\n",
    "    # Predicted KO impact (Bray-Curtis distance to baseline)\n",
    "    p_dis.append(braycurtis(one_pred, Without_knock1))\n",
    "\n",
    "p_dis = np.asarray(p_dis, dtype=float)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"gene1_id\": Perturb_gene1_index,\n",
    "    \"gene2_id\": Perturb_gene2_index,\n",
    "    \"cell_id\":  Perturb_cell_index,\n",
    "    \"k_pred\":   p_dis\n",
    "})\n",
    "print(df)\n",
    "df.to_csv(f'./results/Impact_results_doubleKO.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:forpytorch]",
   "language": "python",
   "name": "conda-env-forpytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
