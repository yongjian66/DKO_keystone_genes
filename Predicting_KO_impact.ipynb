{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import csv\n",
    "import itertools\n",
    "import math\n",
    "import os.path\n",
    "import pdb\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from collections import Counter\n",
    "from itertools import permutations, product\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from scipy.integrate import solve_ivp, odeint\n",
    "from scipy.spatial.distance import braycurtis\n",
    "from scipy.stats import entropy, pearsonr, spearmanr\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DKO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(ztrn,ptrn,mb_size):\n",
    "    s = torch.from_numpy(np.random.choice(np.arange(ptrn.size(dim=0), dtype=np.int64), mb_size, replace=False))\n",
    "    batch_p = ztrn[s,:]\n",
    "    batch_q = ptrn[s,:]\n",
    "    batch_t = t[:batch_time]\n",
    "    return batch_p.to(device), batch_q.to(device)\n",
    "\n",
    "\n",
    "def loss_bc(p_i,q_i):\n",
    "    return torch.sum(torch.abs(p_i-q_i))/torch.sum(torch.abs(p_i+q_i))\n",
    "\n",
    "\n",
    "def process_data(P):\n",
    "    #Z = P.copy()\n",
    "    #Z[Z!=0] = 1\n",
    "    P = P/P.sum(axis=0)[np.newaxis,:]\n",
    "    #Z = Z/Z.sum(axis=0)[np.newaxis,:]\n",
    "    \n",
    "   \n",
    "    P = P.astype(np.float32)\n",
    "#     Z = Z.astype(np.float32)\n",
    "\n",
    "    P = torch.from_numpy(P.T)\n",
    "    #Z = torch.from_numpy(Z.T)\n",
    "    return P\n",
    "\n",
    "\n",
    "class ODEFunc(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ODEFunc, self).__init__()\n",
    "        self.fcc1 = torch.nn.Linear(N, N)\n",
    "        self.fcc2 = torch.nn.Linear(N, N)\n",
    "\n",
    "    def forward(self, y):\n",
    "        out = self.fcc1(y)\n",
    "        out = self.fcc2(out)\n",
    "        return torch.mul(y,torch.abs(out))/torch.sum(torch.mul(y,torch.abs(out)))\n",
    "    \n",
    "def train_reptile(max_epochs,mb,LR,ztrn,ptrn,ztst,ptst,zval,pval,zall,pall):\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "    qtst = np.zeros((ztst.size(dim=0),N))\n",
    "    qtrn = np.zeros((zall.size(dim=0),N))\n",
    "    ltst_pred = np.zeros((ztst.size(dim=0),1))\n",
    "    ltst_ground = np.zeros((ztst.size(dim=0),1))\n",
    "    \n",
    "    func = ODEFunc().to(device)\n",
    "    optimizer = torch.optim.Adam(func.parameters(), lr=LR)\n",
    "\n",
    "    Loss_opt = 1\n",
    "    for e in range(max_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        batch_p, batch_q = get_batch(ztrn,ptrn,mb)\n",
    "        \n",
    "        # loss of the traning set\n",
    "        for i in range(mb):\n",
    "            p_pred = func(batch_p[i]).to(device)\n",
    "            p_pred = torch.reshape(p_pred,(1,N))\n",
    "            if i==0:\n",
    "                loss = loss_bc(p_pred.unsqueeze(dim=0),batch_q[i].unsqueeze(dim=0))\n",
    "            else:\n",
    "                loss = loss + loss_bc(p_pred.unsqueeze(dim=0),batch_q[i].unsqueeze(dim=0))\n",
    "        loss_train.append(loss.item()/mb)\n",
    "\n",
    "\n",
    "        # validation set\n",
    "        for i in range(zval.size(dim=0)):\n",
    "            p_pred = func(zval[i]).to(device)\n",
    "            p_pred = torch.reshape(p_pred,(1,N))\n",
    "            if i==0:\n",
    "                l_val = loss_bc(p_pred.unsqueeze(dim=0),pval[i].unsqueeze(dim=0))\n",
    "            else:\n",
    "                l_val = l_val + loss_bc(p_pred.unsqueeze(dim=0),pval[i].unsqueeze(dim=0))\n",
    "        loss_val.append(l_val.item()/zval.size(dim=0))\n",
    "        if l_val.item()/zval.size(dim=0)<=Loss_opt:\n",
    "            Loss_opt = loss_val[-1]\n",
    "            best_model = copy.deepcopy(func)\n",
    "        #print('epoch = ',e, 'loss = ', l_val.item()/mb)\n",
    "\n",
    "        # update the neural network\n",
    "        func.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e == max_epochs-1:\n",
    "            func = copy.deepcopy(best_model)\n",
    "            if len(ztst.size())==2:\n",
    "                for i in range(ztst.size(dim=0)):\n",
    "                    pred_test = func(ztst[i]).to(device)\n",
    "                    pred_test = torch.reshape(pred_test,(1,N))\n",
    "                    qtst[i,:] = pred_test.detach().numpy()\n",
    "                for i in range(zall.size(dim=0)):\n",
    "                    pred_test = func(zall[i]).to(device)\n",
    "                    pred_test = torch.reshape(pred_test,(1,N))\n",
    "                    qtrn[i,:] = pred_test.detach().numpy()\n",
    "    return loss_train,qtst,qtrn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Generate knockout perturbation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_test: shape = (N_genes, n_perturbations)\n",
    "#   Each column corresponds to one perturbation event.\n",
    "#   A perturbation event is defined by a pair (cell_id, gene_id) indicating that gene_id is knocked out in cell_id. \n",
    "\n",
    "# Recorder: shape = (n_perturbations, 2)\n",
    "#     recording the (cell_id, gene_id) each perturbation\n",
    "\n",
    "# n_perturbations:\n",
    "#   In single-cell data, this equals the total number of knocked-out genes across all cells.\n",
    "#   If you create one KO per gene with expression > 0 in each cell:\n",
    "#       n_perturbations = sum over cells of (number of genes with expression > 0 in that cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 5207.11it/s]\n"
     ]
    }
   ],
   "source": [
    "Orignial = pd.read_csv(f'./data/Ptrain.csv',header = None).values.astype(float)\n",
    "perurbed_times = len(np.nonzero(Orignial)[0])  #if gene expression is more than 0 will be computed\n",
    "\n",
    "perturb_count = 0\n",
    "perturb_matrix = np.zeros((N_genes, perurbed_times))\n",
    "\n",
    "records = np.zeros((perurbed_times, 2),dtype = int)\n",
    "\n",
    "for cell_idx in tqdm(range(N_cells)):\n",
    "    original_cell = Orignial[:, cell_idx].copy()\n",
    "    nonzero_genes = np.nonzero(original_cell)[0]\n",
    "    for gene_idx in nonzero_genes:\n",
    "        perturb_cell = original_cell.copy()\n",
    "        perturb_cell[gene_idx] = 0\n",
    "        \n",
    "        perturb_matrix[:,perturb_count] = perturb_cell\n",
    "        records[perturb_count] = (cell_idx, gene_idx)\n",
    "        perturb_count+=1\n",
    "\n",
    "matrix_df = pd.DataFrame(perturb_matrix)\n",
    "matrix_df.to_csv(f'./Ptest.csv',header = None,index = None)    \n",
    "records_df  = pd.DataFrame(records)\n",
    "records_df.to_csv(f'./Recoder.csv',header = ['cell_index','gene_index'],index = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Predicting the gene expression profile after gene KO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([39343, 100])\n",
      "(39343, 100)\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "max_epochs = 5000\n",
    "device = 'cpu'\n",
    "batch_time = 100\n",
    "t = torch.arange(0.0, 100.0, 0.01)\n",
    "\n",
    "filepath_train = f'./data/Ptrain.csv'\n",
    "P = np.loadtxt(filepath_train,delimiter=',')\n",
    "Z = P.copy()\n",
    "Z[Z>0] = 1\n",
    "\n",
    "pall = process_data((P))\n",
    "zall = process_data(Z)\n",
    "\n",
    "number_of_cols = P.shape[1]\n",
    "random_indices = np.random.choice(number_of_cols, size=int(0.2*number_of_cols), replace=False)\n",
    "P_val = P[:,random_indices]\n",
    "Z_val = Z[:,random_indices]\n",
    "P_train =  P[:,np.setdiff1d(range(0,number_of_cols),random_indices)]\n",
    "Z_train =  Z[:,np.setdiff1d(range(0,number_of_cols),random_indices)]\n",
    "\n",
    "\n",
    "ptrn= process_data((P_train))\n",
    "pval = process_data((P_val))\n",
    "ztrn = process_data(Z_train)\n",
    "zval = process_data(Z_val)\n",
    "\n",
    "filepath_test = f'./data/Ptest.csv'\n",
    "P1 = np.loadtxt(filepath_test,delimiter=',')\n",
    "Z1 = P1.copy()\n",
    "Z1[Z1>0] = 1\n",
    "ptst = process_data((P1))\n",
    "ztst = process_data(Z1)\n",
    "\n",
    "M, N = ptrn.shape\n",
    "\n",
    "print(ztst.shape)\n",
    "# pre training to select the parameter\n",
    "LR = 0.01\n",
    "mb = 20\n",
    "\n",
    "loss_train,qtst,qtrn = train_reptile(max_epochs,mb,LR,ztrn,ptrn,ztst,ptst,zval,pval,zall,pall)\n",
    "np.savetxt(f'./data/PredKO.csv',qtst,delimiter=',')\n",
    "np.savetxt(f'./data/PPred.csv',qtrn,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3：Cacluate the gene KO impact score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_model = np.loadtxt(f'./data/PPred.csv', delimiter=',')# shape: (N_cells,genes)\n",
    "predss = np.loadtxt(f'./data/PredKO.csv', delimiter=',')  # shape: (perturbation, N_genes)\n",
    "records = pd.read_csv(f'./data/Recoder.csv')\n",
    "Perturb_cell_index = list(records['cell_index'])\n",
    "Perturb_gene_index = list(records['gene_index'])\n",
    "\n",
    "\n",
    "p_dis = []\n",
    "for i in range(predss.shape[0]):\n",
    "    c_id = Perturb_cell_index[i] #This cell_id of KO gene_id\n",
    "    \n",
    "    Without_knock =  Original_model[c_id,:].copy()\n",
    "    Without_knock = Without_knock/np.sum(Without_knock)\n",
    "    one_pred = predss[i,:]\n",
    "        \n",
    "    p_dis.append(braycurtis(one_pred, Without_knock))\n",
    "    \n",
    "df = pd.DataFrame({\n",
    "    \"gene_id\":Perturb_gene_index,\n",
    "    \"cell_id\":Perturb_cell_index,\n",
    "    \"k_pred\": p_dis\n",
    "})\n",
    "df.to_csv(f'./results/Impact_results.csv',index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:forpytorch]",
   "language": "python",
   "name": "conda-env-forpytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
